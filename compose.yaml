services:
  local_llm:
    provider:
      type: model
      options:
        model: ai/smollm2
  fastapi:
    build:
      context: ./app
    ports:
      - "8000:8000"
    depends_on:
      - local_llm

  ui:
    build:
      context: ./ui
    ports:
      - "8501:8501"
    depends_on:
      - fastapi
   